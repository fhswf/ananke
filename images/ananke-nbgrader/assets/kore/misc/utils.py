import fcntl
import grp
import hashlib
import json
import logging
import os
from glob import glob
from pathlib import Path
from string import capwords
from subprocess import run, CalledProcessError
from typing import List, Optional, Counter, Tuple

import numpy as np
from flask import Response
from flask import request as flask_request
from werkzeug.exceptions import BadRequestKeyError

from exceptions import AutogeneratedFileError
from models.subset import Subset


def load_info(path: str) -> dict:
    try:
        with open(file=path, mode='r') as info_file:
            return json.load(info_file)
    except FileNotFoundError:
        logging.error(f'Info file not found: {path}')
        raise
    except PermissionError:
        logging.debug(f'Info file not readable: {path}')
        run(['chmod', '600', path], check=True)
        with open(file=path, mode='r') as info_file:
            return json.load(info_file)
    except CalledProcessError:
        logging.error('Failed to change file permissions or execute the command.')
        raise
    except OSError:
        logging.error(f'Failed to open the info file: {path}')
        raise


def make_course_id(lti_state: dict) -> Tuple[str, str, str, str]:
    """
    Make course ID, course title, grader username from LTI data.

    Parameters
    ----------
    lti_state : dict
        The authentication dict for the user.

    Returns
    -------
    tuple[str, str, str]
        The returned tuple contains the course id, course title and the grader user as strings.
    """

    deployment_id = lti_state.get('https://purl.imsglobal.org/spec/lti/claim/deployment_id', '0')
    resource_link_id = lti_state.get('https://purl.imsglobal.org/spec/lti/claim/resource_link').get('id')
    resource_link_title = lti_state.get('https://purl.imsglobal.org/spec/lti/claim/resource_link').get('title')
    context_title = lti_state.get('https://purl.imsglobal.org/spec/lti/claim/context', {}).get('title')

    h = hashlib.shake_256(f'{deployment_id}-{resource_link_id}'.encode())
    course_id = 'c-' + h.hexdigest(8)
    grader_user = course_id[0:32]

    if resource_link_title and context_title:
        course_title = f'{context_title} - {resource_link_title}'
    elif resource_link_title:
        course_title = resource_link_title
    elif context_title:
        course_title = context_title
    else:
        course_title = 'No title available'
    course_title_long = f'{course_title} ({course_id})'.replace('\'', '')
    course_title_short = f'{course_title}'.replace('\'', '')

    return course_id, course_title_long, course_title_short, grader_user


def read_autogenerated_config(autogenerated_file_path: str) -> Tuple[list, list, dict]:
    """
    Read services, roles and groups from the autogenerated configuration file.

    Parameters
    ----------
    autogenerated_file_path : str
        Path to the autogenerated configuration file.

    Returns
    -------
    tuple[list, list, dict]
         The returned tuple contains the services (list), the roles (list) and the groups (dict).
    """

    try:
        with open(file=autogenerated_file_path, mode='r') as autogenerated_file:
            # Read Python code from config file.
            logging.debug('Reading autogenerated service configuration.')
            config_code = autogenerated_file.read()
    except FileNotFoundError:
        # File is not present and a new one will be created.
        logging.debug('No autogenerated service file found! A new one will be created.')
        write_autogenerated_config(autogenerated_file_path=autogenerated_file_path, services=[], roles=[], groups={})
        config_code = ''
    except PermissionError:
        logging.debug('Autogenerated services files not readable!')
        run(['chmod', '600', autogenerated_file_path], check=True)
        with open(file=autogenerated_file_path, mode='r') as autogenerated_file:
            logging.debug('Reading autogenerated service configuration.')
            config_code = autogenerated_file.read()
    except CalledProcessError:
        logging.error('Command cannot be executed!')
        raise AutogeneratedFileError

    # Modify Python code.
    logging.debug('Extracting services, roles and groups from file.')
    config_code = config_code.replace('c = get_config()', '')
    config_code = config_code.replace('c.JupyterHub.services', 'services')
    config_code = config_code.replace('c.JupyterHub.load_roles', 'roles')
    config_code = config_code.replace('c.JupyterHub.load_groups', 'groups')

    # Execute Python code.
    services, roles, groups = [], [], {}
    exec(config_code)

    return services, roles, groups


def write_autogenerated_config(autogenerated_file_path: str, services: list, roles: list, groups: dict) -> None:
    """
    Write services, roles and groups to a Python file. Which is read and used by the JupyterHub after next restart.

    Parameters
    ----------
    autogenerated_file_path : str
        Path to the autogenerated configuration file.

    services : list
        A list containing the services.

    roles : list
        A list containing the roles.

    groups : dict
        A dict containing the groups.

    Returns
    -------
    None
    """

    logging.debug('Writing autogenerated service configuration.')

    # Compose code to be written.
    config_code = '# Autogenerated nbgrader course configuration (DO NOT MODIFY)\n\n'
    config_code += 'c = get_config()\n\n'

    config_code += '# Services\n'
    for service in services:
        config_code += 'c.JupyterHub.services.append(' + str(service) + ')\n'
    config_code += '\n'

    config_code += '# Roles\n'
    for role in roles:
        config_code += 'c.JupyterHub.load_roles.append(' + str(role) + ')\n'
    config_code += '\n'

    config_code += '# Groups\n'
    config_code += 'c.JupyterHub.load_groups.update(' + str(groups) + ')\n'

    # Write code to file.
    try:
        with open(file=autogenerated_file_path, mode='w') as autogenerated_file:
            fcntl.flock(autogenerated_file, fcntl.LOCK_EX)
            autogenerated_file.write(config_code)
            fcntl.flock(autogenerated_file, fcntl.LOCK_UN)
        run(['chmod', '600', autogenerated_file_path], check=True)
    except CalledProcessError:
        logging.error('Command cannot be executed!')
        raise AutogeneratedFileError
    except PermissionError:
        logging.debug('Autogenerated services files not readable!')


def get_hub_base_url(lti_state: dict) -> str:
    """
    Read base url of JupyterHub from lti state json.

    Parameters
    ----------
    lti_state : dict
        lti state file (json) containing lti parameters.

    Returns
    -------
    str
        The base url of the JupyterHub as string.
    """

    base_url = lti_state['https://purl.imsglobal.org/spec/lti/claim/target_link_uri']
    base_url = '/'.join(base_url.strip('/').split('://')[-1].split('/')[1:]) + '/'
    logging.debug(f'Base url of JupyterHub as retrieved from the LTI state file: {base_url}.')

    base_url = '' if base_url == '/' else base_url

    return base_url


def get_course_list(autogenerated_file_path: str, subset: Subset = Subset.ALL) -> Response:
    try:
        user_name = flask_request.args.get('user')
        logging.debug(f'User: {user_name}')
    except BadRequestKeyError:
        logging.error('Request key is not in form!')
        return Response(response=json.dumps({'message': 'BadRequestKeyError'}), status=500)

    # Access list of 'owned' groups, this is necessary to copy assignments stored at '/home/FORMGRADER_USER' and verifying access rights.
    try:
        _, _, groups = read_autogenerated_config(autogenerated_file_path=autogenerated_file_path)
    except AutogeneratedFileError:
        return Response(response=json.dumps({'message': 'AutogeneratedFileError'}), status=500)

    # Generating the Subset.ACTIVE course list.
    owned_groups = [
        group.lstrip('formgrade-')
        for group in groups
        if user_name in groups.get(group)
    ]
    base_paths = [
        item.path.removesuffix('/')
        for item in os.scandir('/home')
        if item.is_dir() and grp.getgrgid(os.stat(item.path).st_gid)[0] in owned_groups
    ]
    logging.debug(f'Owned groups: {owned_groups}')
    logging.debug(f'Base paths: {base_paths}')

    # Note: Currently there will no filtering based on the fact if there are *.ipynb files present.
    active_course_paths = [
        course.removesuffix('/')
        for base_path in base_paths
        for course in glob(f'{base_path}/course_data/')
    ]

    # Exit early if there are no active courses.
    if not active_course_paths:
        logging.error('No active courses found.')
        return Response(response=json.dumps({'message': 'NoActiveCoursesFound'}), status=500)

    if subset == Subset.ACTIVE:
        # Check if list of active course paths is empty and return a message and status code indication that. Otherwise, generate response with unique names for courses.
        active_course_paths = sorted(active_course_paths)
        logging.debug(f'Sorted active course paths: {active_course_paths}')

        try:
            unique_course_names = generate_unique_course_names(active_paths=active_course_paths)
        except (FileNotFoundError, PermissionError, CalledProcessError, OSError) as e:
            return Response(response=json.dumps({'message': type(e).__name__}), status=500)

        course_list = {
            'message': 'List of courses successfully retrieved.',
            'names': unique_course_names,
            'paths': active_course_paths
        }
        logging.info(f'Generated course list: {course_list}')

        return Response(response=json.dumps(course_list), status=200)

    if subset == Subset.ALL:
        backed_up_course_paths = [
            course.removesuffix('/')
            for course in glob(pathname=f'/var/lib/private/{user_name}/*/')
        ]

        # Sort the lists and generate combined list.
        active_course_paths = sorted(active_course_paths)
        backed_up_course_paths = sorted(backed_up_course_paths)

        # Generate names to display in the dropdown menu of the kore extension.
        try:
            unique_course_names = generate_unique_course_names(active_paths=active_course_paths, backed_up_paths=backed_up_course_paths)
        except (FileNotFoundError, PermissionError, CalledProcessError, OSError) as e:
            return Response(response=json.dumps({'message': type(e).__name__}), status=500)

        course_list = {
            'message': 'List of courses successfully retrieved.',
            'names': unique_course_names,
            'paths': active_course_paths + backed_up_course_paths,
        }
        logging.info(f'Generated course list: {course_list}')

        return Response(response=json.dumps(course_list), status=200)


def get_assignment_list(autogenerated_file_path: str) -> Response:
    try:
        user_name = flask_request.args.get('user')
        logging.debug(f'User: {user_name}')
    except BadRequestKeyError:
        logging.error('Request key is not in form!')
        return Response(response=json.dumps({'message': 'BadRequestKeyError'}), status=500)

    logging.info(f'User {user_name} is generating list of assignments.')

    # Access list of 'owned' groups, this is necessary to copy assignments stored at '/home/FORMGRADER_USER' and verifying access rights.
    try:
        _, _, groups = read_autogenerated_config(autogenerated_file_path=autogenerated_file_path)
    except AutogeneratedFileError:
        return Response(response=json.dumps({'message': 'AutogeneratedFileError'}), status=500)

    # Generating the assignment list of active courses.
    owned_groups = [group.lstrip('formgrade-') for group in groups if user_name in groups.get(group)]
    base_paths = [item.path.removesuffix('/') for item in os.scandir('/home') if item.is_dir() and grp.getgrgid(os.stat(item.path).st_gid)[0] in owned_groups]
    logging.debug(f'Owned groups: {owned_groups}')
    logging.debug(f'Base paths: {base_paths}')

    active_assignment_paths = [
        str(assignment_path)
        for base_path in base_paths
        if Path(f'{base_path}/course_data/source/').exists()
        for assignment_path in Path(f'{base_path}/course_data/source/').glob('*/')
        if assignment_path.is_dir() and assignment_path.parts
    ]

    backed_up_assignment_paths = [
        str(assignment_path)
        for source_path in Path(f'/var/lib/private/{user_name}').glob('*/source/')
        if source_path.is_dir()
        for assignment_path in source_path.glob('*/')
        if assignment_path.is_dir() and not assignment_path.name.startswith('.')
    ]

    # Sort the lists and generate combined list.
    active_assignment_paths = sorted(active_assignment_paths)
    backed_up_assignment_paths = sorted(backed_up_assignment_paths)

    # Generate names to display in the dropdown menu of the kore extension.
    try:
        unique_assignment_names = generate_unique_assignment_names(active_paths=active_assignment_paths, backed_up_paths=backed_up_assignment_paths)
    except (FileNotFoundError, PermissionError, CalledProcessError, OSError) as e:
        return Response(response=json.dumps({'message': type(e).__name__}), status=500)

    course_list = {
        'message': 'List of assignments successfully retrieved.',
        'names': unique_assignment_names,
        'paths': active_assignment_paths + backed_up_assignment_paths,
    }
    logging.info(f'Generated course list: {course_list}')

    return Response(response=json.dumps(course_list), status=200)


def get_problem_list(autogenerated_file_path: str) -> Response:
    try:
        user_name = flask_request.args.get('user')
        logging.debug(f'User: {user_name}')
    except BadRequestKeyError:
        logging.error('Request key is not in form!')
        return Response(response=json.dumps({'message': 'BadRequestKeyError'}), status=500)

    logging.info(f'User {user_name} is generating list of assignments.')

    # Access list of 'owned' groups, this is necessary to copy assignments stored at '/home/FORMGRADER_USER' and verifying access rights.
    try:
        _, _, groups = read_autogenerated_config(autogenerated_file_path=autogenerated_file_path)
    except AutogeneratedFileError:
        return Response(response=json.dumps({'message': 'AutogeneratedFileError'}), status=500)

    # Generating the assignment list of active courses.
    owned_groups = [group.lstrip('formgrade-') for group in groups if user_name in groups.get(group)]
    base_paths = [item.path.removesuffix('/') for item in os.scandir('/home') if item.is_dir() and grp.getgrgid(os.stat(item.path).st_gid)[0] in owned_groups]
    logging.debug(f'Owned groups: {owned_groups}')
    logging.debug(f'Base paths: {base_paths}')

    active_problem_paths = [
        str(problem_path)
        for base_path in base_paths
        for problem_path in Path(f'{base_path}/course_data/source/').rglob('*.ipynb')
        if problem_path.is_file() and not any(part.name.startswith('.') for part in problem_path.parents)
    ]

    backed_up_problem_paths = [
        str(problem_path)
        for source_path in Path(f'/var/lib/private/{user_name}').glob('*/source/')
        if source_path.is_dir()
        for problem_path in source_path.rglob('*.ipynb')
        if problem_path.is_file() and not any(part.name.startswith('.') for part in problem_path.parents)
    ]

    # Sort the lists and generate combined list.
    active_problem_paths = sorted(active_problem_paths)
    backed_up_problem_paths = sorted(backed_up_problem_paths)

    # Generate names to display in the dropdown menu of the kore extension.
    try:
        unique_problem_names = generate_unique_problem_names(active_paths=active_problem_paths, backed_up_paths=backed_up_problem_paths)
    except (FileNotFoundError, PermissionError, CalledProcessError, OSError) as e:
        return Response(response=json.dumps({'message': type(e).__name__}), status=500)

    course_list = {
        'message': 'List of problems successfully retrieved.',
        'names': unique_problem_names,
        'paths': active_problem_paths + backed_up_problem_paths,
    }
    logging.info(f'Generated course list: {course_list}')

    return Response(response=json.dumps(course_list), status=200)


def generate_unique_course_names(active_paths: List[str], backed_up_paths: Optional[List[str]] = None) -> List[str]:
    """
    Generate a list of unique course names from active and backed-up course paths.

    Parameters
    ----------
    active_paths : List[str]
        List of paths to active course directories.
    backed_up_paths : Optional[List[str]], default=None
        List of paths to backed-up course directories. If None, only active course names are processed.

    Returns
    -------
    List[str]
        A list of unique course names, with "(Backup)" appended to backed-up course names.
    """

    # Generate active course names.
    active_names = []
    for active_path in active_paths:
        user_name = active_path.split('/')[2]
        info_file_path = f'/home/{user_name}/course_data/info.json'
        try:
            info = load_info(info_file_path)
            active_names.append(info['title_short'])
        except (FileNotFoundError, PermissionError, CalledProcessError, OSError):
            raise

    logging.debug(f'Active course names: {active_names}')

    # Generate backed-up course names if provided.
    backed_up_names = []
    if backed_up_paths:
        backed_up_names = [f"{path.split('/')[-1]} (Backup)" for path in backed_up_paths]
        logging.debug(f'Backed up course names: {backed_up_names}')

    # Combine and ensure uniqueness.
    all_names = [active_names, backed_up_names] if backed_up_paths else [active_names]

    unique_course_names = []
    for course_names in all_names:
        unique_array, unique_count = np.unique(course_names, return_counts=True)

        if not np.all(unique_count == 1):
            counts = dict(Counter[course_names])
            course_names = [key if i == 0 else key + f' ({i})' for key in unique_array for i in range(counts[key])]

        course_names = [capwords(name.replace('_', ' ')) for name in course_names]
        unique_course_names.extend(course_names)

    logging.debug(f'Unique course names: {unique_course_names}')
    return unique_course_names


def generate_unique_assignment_names(active_paths: List[str], backed_up_paths: Optional[List[str]] = None) -> List[str]:
    """
    Generate a list of unique assignment names from active and backed-up assignment paths.

    Parameters
    ----------
    active_paths : List[str]
        List of paths to active assignment directories.
    backed_up_paths : Optional[List[str]], default=None
        List of paths to backed-up assignment directories. If None, only active assignment names are processed.

    Returns
    -------
    List[str]
        A list of unique course names, with "(Backup)" appended to backed-up course names.
    """

    # Generate active assignment names.
    active_names = []
    for active_path in active_paths:
        user_name = active_path.split('/')[2]
        info_file_path = f'/home/{user_name}/course_data/info.json'
        try:
            info = load_info(info_file_path)
            title_short = info['title_short']
            active_names.append(f"{active_path.removesuffix('/').split('/')[-1]} ({title_short})")
        except (FileNotFoundError, PermissionError, CalledProcessError, OSError):
            raise

    logging.debug(f'Active assignment names: {active_names}')

    # Generate backed-up course names if provided.
    backed_up_names = []
    if backed_up_paths:
        backed_up_names = [f"{path.split('/')[-1]} (Backup, {path.split('/')[-3]})" for path in backed_up_paths]
        logging.debug(f'Backed up assignment names: {backed_up_names}')

    # Combine and ensure uniqueness.
    all_names = [active_names, backed_up_names] if backed_up_paths else [active_names]

    unique_assignment_names = []
    for assignment_names in all_names:
        unique_array, unique_count = np.unique(assignment_names, return_counts=True)

        if not np.all(unique_count == 1):
            counts = dict(Counter[assignment_names])
            assignment_names = [key if i == 0 else key + f' ({i})' for key in unique_array for i in range(counts[key])]

        assignment_names = [capwords(name.replace('_', ' ')) for name in assignment_names]
        unique_assignment_names.extend(assignment_names)

    logging.debug(f'Unique course names: {unique_assignment_names}')
    return unique_assignment_names


def generate_unique_problem_names(active_paths: List[str], backed_up_paths: Optional[List[str]] = None) -> List[str]:
    """
    Generate a list of unique problem names from active and backed-up problem paths.

    Parameters
    ----------
    active_paths : List[str]
        List of paths to active assignment directories.
    backed_up_paths : Optional[List[str]], default=None
        List of paths to backed-up assignment directories. If None, only active assignment names are processed.

    Returns
    -------
    List[str]
        A list of unique problem names, with "(Backup)" appended to backed-up course names.
    """

    # Generate active assignment names.
    active_names = []
    for active_path in active_paths:
        # TODO can be optimized
        user_name = active_path.split('/')[2]
        info_file_path = f'/home/{user_name}/course_data/info.json'
        try:
            info = load_info(info_file_path)
            title_short = info['title_short']
            active_names.append(f"{active_path.removesuffix('.ipynb').split('/')[-1]} ({title_short}, {active_path.removesuffix('/').split('/')[-2]})")
        except (FileNotFoundError, PermissionError, CalledProcessError, OSError):
            raise

    logging.debug(f'Active assignment names: {active_names}')

    # Generate backed-up course names if provided.
    backed_up_names = []
    if backed_up_paths:
        backed_up_names = [f"{path.removesuffix('.ipynb').split('/')[-1]} (Backup, {path.split('/')[-4]}, {path.split('/')[-2]})" for path in backed_up_paths]
        logging.debug(f'Backed up assignment names: {backed_up_names}')

    # Combine and ensure uniqueness.
    all_names = [active_names, backed_up_names] if backed_up_paths else [active_names]

    unique_assignment_names = []
    for assignment_names in all_names:
        unique_array, unique_count = np.unique(assignment_names, return_counts=True)

        if not np.all(unique_count == 1):
            counts = dict(Counter[assignment_names])
            assignment_names = [key if i == 0 else key + f' ({i})' for key in unique_array for i in range(counts[key])]

        assignment_names = [capwords(name.replace('_', ' ')) for name in assignment_names]
        unique_assignment_names.extend(assignment_names)

    logging.debug(f'Unique course names: {unique_assignment_names}')
    return unique_assignment_names
